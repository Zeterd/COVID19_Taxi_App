install.packages("devtools",repos=c(CRAN = "http://cran.rstudio.com"))
devtools::install_github("nickpoison/astsa")
library(astsa)
tsplot(jj, type="o", ylab="Quarterly Earnings per Share")
tsplot(gas, type="o", ylab="Gas Prices")
tsplot(hor, type="o", ylab="Hawaiian occupancy rates")
tsplot(hor, type="c", ylab="Hawaiian occupancy rates")
tsplot(hor, type="o", ylab="Hawaiian occupancy rates")
acf(hor)
tsplot(hor, type="o", ylab="Hawaiian occupancy rates")
acf(hor)
adf.test(hor)
library(tseries)
install.packages('tseries')
library(tseries)
library(tseries)
library(tseries)
library(quantmod)
library(quantmod)
library(tseries)
install.packages("tseries")
library(tseries)
install.packages("quadprog")
install.packages("tseries",repos=c(CRAN = "http://cran.rstudio.com"))
install.packages("tseries",repos=c(CRAN = "https://cran.rstudio.com/src/contrib/quadprog_1.5-7.tar.gz"))
install.packages("quadprog",repos=c(CRAN = "https://cran.rstudio.com/src/contrib/quadprog_1.5-7.tar.gz"))
install.packages("tseries",repos=c(CRAN = "https://CRAN.R-project.org/package=tseries"))
tsplot(hor, type="o", ylab="Hawaiian occupancy rates")
library(astsa)
tsplot(hor, type="o", ylab="Hawaiian occupancy rates")
library(astsa)
tsplot(hor, type="o", ylab="Hawaiian occupancy rates")
mean(hor)
acf(hor)
Box.test(x, lag = 1, type = c("Box-Pierce", "Ljung-Box"), fitdf = 0)
Box.test(hor, lag = 1, type = c("Box-Pierce", "Ljung-Box"), fitdf = 0)
Box.test(hor, lag = 20, type = c("Box-Pierce", "Ljung-Box"), fitdf = 0)
Box.test(hor, lag = 5, type = c("Box-Pierce", "Ljung-Box"), fitdf = 0)
Box.test(hor, lag = 1, type = c("Box-Pierce", "Ljung-Box"), fitdf = 0)
---
title: "TPC-1"
author: "Solange Samapio"
date: "30/09/2019"
output: html_document
---
knitr::opts_chunk$set(echo = TRUE)
tsplot(hor, type="o", ylab="Hawaiian occupancy rates")
Box.test(hor, lag = 1, type = c("Box-Pierce", "Ljung-Box"), fitdf = 0)
acf(hor)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
tsplot(hor, type="o", ylab="Hawaiian occupancy rates")
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
tsplot(hor, type="o", ylab="Hawaiian occupancy rates")
tinytex::install_tinytex()
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
library(astsa)
tsplot(hor, type="o", ylab="Hawaiian occupancy rates")
library(astsa)
tsplot(hor, type="o", ylab="Hawaiian occupancy rates")
decompose(hor)
x = decompose(hor)
plot(x)
tsplot(hor, type="o", ylab="Hawaiian occupancy rates")
tsplot(cpg, type="o", ylab="Hard Drive Cost per GB")
acf(cpg)
tsplot(cpg, type="o", ylab="Hard Drive Cost per GB")
tsplot(gas, type="o", ylab="Gas Prices")
acf(gas)
tsplot(gas, type="o", ylab="Gas Prices")
acf(gas)
tsplot(gas, type="o", ylab="Gas Prices")
getwd()
x <- getwd()
list.files(x,recursive=TRUE)
knit_with_parameters('~/Área de Trabalho/TPC-1.Rmd')
knitr::opts_chunk$set(echo = TRUE)
install.packages(c("forecast", "fpp"))
acfT=ARMAacf(ar=0.2,lag.max=(100/4))
plot(acfT[-1],type="h",xlab="lag",ylab="ACF & SACF",ylim=c(-1,1),
main=paste("AR(1)","a=0.2"))
abline(h=0)
acfT=ARMAacf(ar=0.7,lag.max=(100/4))
plot(acfT[-1],type="h",xlab="lag",ylab="ACF & SACF",ylim=c(-1,1),
main=paste("AR(1)","a=0.7"))
abline(h=0)
abline(h=0)
acfT=ARMAacf(ar=0.2, lag.max=(100/4))
plot(acfT[-1],type="h",xlab="lag",ylab="ACF & SACF",ylim=c(-1,1),main=paste("AR(1)","a=",0.2))
abline(h=0)
install.packages("fpc")
install.packages("cluster")
install.packages("factoExtra")
install.packages("factoextra")
library(cluster)
library(fpc)
library(factoextra)
load("Iris")
load("iris")
data("iris")
force(iris)
library(dplyr)
iris1 <- %>% select(-Species)
iris1 <- iris %>% select(-Species)
summary(iris1)
iris2 <- dist(iris1)
summaru(iris2)
summary(iris2)
as.matrix(iris2)
dm <- as.matrix(dist(iris2))
dm[1:5,1:5]
scale(iris2, center=TRUE, scale=TRUE)
scale(iris1, center=TRUE, scale=TRUE)
k3 <- kmeans(iris.scale, centers=3)
iris.scale <- scale(iris1, center=TRUE, scale=TRUE)
k3 <- kmeans(iris.scale, centers=3)
k3
k3$size
k3
k3 <- kmeans(iris.scale, centers=3)
k3
fviz_cluster(k3,iris.scale)
si_coefs_k3 <- silhouette(k3$cluster,as.matrix(dist(iris.scale)))
fviz_silhouette(si_coefs_k3) + coord_flip()
fviz_silhouette(si_coefs_k3)
iris.tbl <- tbl_df(iris[,-5])
iris.scale <- iris.tbl %>% mutate_all(scale)
k3 <- kmeans(iris.scale, centers=3)
k3
k3
fviz_cluster(k3,iris.scale)
si_coefs_k3 <- silhouette(k3$cluster,as.matrix(dist(iris.scale)))
fviz_silhouette(si_coefs_k3)
fviz_nbclust(iris.scale, kmeans, method = "silhoutte")
fviz_nbclust(iris.scale, kmeans, method = "silhouette")
x <- arima.sim(n = 500, list(ar=c(0.5,0.3), ma=c(1,0.7)))
plot(x)
tsplot(x)
library(astsa)
tsplot(x)
library(forecast)
auto.arima()
auto.arima(x)
auto.arima(x)
auto.arima(x)
auto.arima(x)
auto.arima(x)
auto.arima(x)
auto.arima(x)
auto.arima(x)
auto.arima(x)
auto.arima(x)
auto.arima(x)
auto.arima(x)
auto.arima(x)
auto.arima()
auto.arima()
auto.arima()
x <- arima.sim(n = 500, list(ar=c(0.5,0.3), ma=c(1,0.7)))
auto.arima(x)
x <- arima.sim(n = 500, list(ar=c(0.5,0.3), ma=c(1,0.7)))
auto.arima(x)
x <- arima.sim(n = 500, list(ar=c(0.5,0.3), ma=c(1,0.7)))
auto.arima(x)
x <- arima.sim(n = 500, list(ar=c(0.5,0.3), ma=c(1,0.7)))
auto.arima(x)
x <- arima.sim(n = 500, list(ar=c(0.5,0.3), ma=c(1,0.7)))
auto.arima(x)
x <- arima.sim(n = 500, list(ar=c(0.5,0.3), ma=c(1,0.7)))
auto.arima(x)
auto.arima(x, trace=TRUE)
auto.arima(x, trace=TRUE, d=0)
simulate_time_series <- function(x) {}
while(sum(matrixAIC) != 1000) {
print('Iteration number:')
i = i + 1
print(i)
x <- arima.sim(model=list(ar=c(0.5,0.3,0), ma=0.7), n = 500)
aic <-  auto.arima(x, d=0, ic=c("aic"))
bic <-  auto.arima(x, d=0, ic=c("bic"))
pAIC <- aic$arma[1] + 1
qAIC <- aic$arma[2] + 1
pBIC <- bic$arma[1] + 1
qBIC <- bic$arma[2] + 1
matrixAIC[pAIC,qAIC] = matrixAIC[pAIC,qAIC] + 1
matrixBIC[pBIC,qBIC] = matrixBIC[pBIC,qBIC] + 1
}
library(forecast)
set.seed(1)
matrixAIC <- matrix(0, nrow=6, ncol=6)
matrixBIC <- matrix(0, nrow=6, ncol=6)
colnames(matrixAIC) <- c('0','1','2','3','4','5')
rownames(matrixAIC) <- c('0','1','2','3','4','5')
colnames(matrixBIC) <- c('0','1','2','3','4','5')
rownames(matrixBIC) <- c('0','1','2','3','4','5')
i = 0
while(sum(matrixAIC) != 1000) {
print('Iteration number:')
i = i + 1
print(i)
x <- arima.sim(model=list(ar=c(0.5,0.3,0), ma=0.7), n = 500)
aic <-  auto.arima(x, d=0, ic=c("aic"))
bic <-  auto.arima(x, d=0, ic=c("bic"))
pAIC <- aic$arma[1] + 1
qAIC <- aic$arma[2] + 1
pBIC <- bic$arma[1] + 1
qBIC <- bic$arma[2] + 1
matrixAIC[pAIC,qAIC] = matrixAIC[pAIC,qAIC] + 1
matrixBIC[pBIC,qBIC] = matrixBIC[pBIC,qBIC] + 1
}
sprintf('Total iterations: %i', i)
matrixAIC
matrixBIC
#sou a solange e sou muito totó
library(dplyr)
library(knitr)
library(DT)
library(xtable)
table[2,] = c(modelfit["0"])
table[2,] = c("0")
table = matrix(NA, nrow=7, ncol=7)
colnames(table) = c("0","1", "2", "3", "4", "5")
rownames(table) = c("0","1", "2", "3", "4", "5")
colnames(table) <- c("0","1", "2", "3", "4", "5")
table <- matrix(c(0,0,0,0,0,0,
0,65,287,100,15,0,
0,334,39,29,6,0,
0,54,27,8,4,0,
5,9,7,5,3,0,
1,1,0,0,0,1), nrow=6,ncol,6,byrow=TRUE)
table <- matrix(c(0,0,0,0,0,0,
0,65,287,100,15,0,
0,334,39,29,6,0,
0,54,27,8,4,0,
5,9,7,5,3,0,
1,1,0,0,0,1) nrow=6,ncol,6,byrow=TRUE)
table <- matrix(c(0,0,0,0,0,0,
0,65,287,100,15,0,
0,334,39,29,6,0,
0,54,27,8,4,0,
5,9,7,5,3,0,
1,1,0,0,0,1), nrow=6,ncol=6,byrow=TRUE)
table
sum(table)
colnames(table) <- c("0","1", "2", "3", "4", "5")
rownames(table) = c("0","1", "2", "3", "4", "5")
table
library(xtable)
print(xtable(table), type('html'))
print(xtable(table), type='html')
print(xtable(table))
("pander")
library("pander")
install.packages("pander")
library("pander")
pandoc.table(table)
library(knitr)
library(kableExtra
;
library(knitr)
library(kableExtra)
kable(table)
library(tableHTML)
library(tableHTML)
install.packages("tableHTML")
table %>%
tableHTML(rownames = TRUE,
caption = 'Table 4: Bucket Table') %>%
add_css_conditional_column(columns = 6:6,
conditional = "between",
between = c(-Inf, Inf),
css = list(c("text-align"),
c("right !important"))) %>%
add_css_header(css = list(c("text-align"),
c("right !important")),
headers = 6:6) %>%
add_css_caption(css = list(c("text-align", "margin-bottom"),
c("left", "10px")))
kable(table, caption = "Group Rows")
library(dplyr)
library(dplyr)
install.packages("tidyverse")
library(formattable)
install.packages("formattable")
library(formattable)
formattable(ds)
ds <- data.frame("p" = c(0,1,2,3,4,5),
"0" = c(0,0,0,0,0,0),
"1" = c(0,65,287,100,15,0),
"2" = c(0,334,39,29,6,0),
"3" = c(0,54,27,8,4,0),
"4" = c(5,9,7,5,3,0),
"5" = c(1,1,0,0,0,1))
formattable(ds)
formattable(table)
sum(table)
library(e1071)
library(rpart)
library(MASS)
library(mlbench)
install.packages("mlbench")
library(mlbench)
install.packages("performanceEstimation.")
library(performanceEstimation)
install.packages("performanceEstimation")
library(performanceEstimation)
load("Boston")
load(Boston)
load(Boston.package, "MASS")
load(Boston.package = "MASS")
data(Boston.package = "MASS")
data(Boston)
summary(Boston)
res <- performanceEstimation(PredTask(medv~ .,Boston),
c(workflowVariants(learner="lm"),
workflowVariants(learner="rpart",learner.pars=list(maxdepth=1:5,cp=0)),
workflowVariants(learner="rpart")),
EstimationTask(metrics = c("mse","mae"), method = CV()))
pres <- pairedComparisons(res)
pres
signifDiffs(pres)
pres <- pairedComparisons(res, baseline="lm")
pres <- performanceEstimation(res,baseline = "rport")
pres <- performanceEstimation(res,baseline = "rport")
data("PimIndiansSiabetes")
data("PimIndiansDiabetes")
data("PiamaIndiansDiabetes")
data("PimaIndiansDiabetes")
res <- performanceEstimation(PredTask(diabetes~.,PimaIndiansDiabetes),
Workflow(learns="naiveBayes"),
EstimationResults(metrics=c("acc","F","rec", "prec")))
res <- performanceEstimation(PredTask(diabetes~.,PimaIndiansDiabetes),
workflow(learns="naiveBayes"),
EstimationResults(metrics=c("acc","F","rec", "prec")))
res <- performanceEstimation(PredTask(diabetes~.,PimaIndiansDiabetes),
workflow(learner="naiveBayes"),
EstimationResults(metrics=c("acc","F","rec", "prec")))
res <- performanceEstimation(PredTask(diabetes~.,PimaIndiansDiabetes),
Workflow(learner="naiveBayes"),
EstimationResults(metrics=c("acc","F","rec", "prec")))
res <- performanceEstimation(PredTask(diabetes~.,PimaIndiansDiabetes),
Workflow(learner="naiveBayes"),
EstimationResults(metrics=c("acc","F","rec", "prec")))
nrow(PimaIndiansDiabetes)
res <- performanceEstimation(PredTask(diabetes ~.,PimaIndiansDiabetes),
Workflow(learner="naiveBayes"),
EstimationResults(metrics=c("acc","F","rec", "prec")))
res <- performanceEstimation(PredTask(diabetes ~.,PimaIndiansDiabetes),
Workflow(learner="naiveBayes"),
EstimationTask(metrics=c("acc","F","rec", "prec")))
t <- rpart(diabetes ~.,PimaIndiansDiabetes)
rpart.plot(t)
t <- rpart(diabetes ~.,PimaIndiansDiabetes)
rpart.plot(t)
install.packages(arules)
install.packages("arules")
install.packages("arulesViz")
load("Groceries")
library(arules)
library(arulesViz)
data("Groceries")
data("Groceries")
Groceries
#1)
class(Groceries)
#2)
summary(Groceries)
Groceries
#c)
size(Groceries)
#d)
inspect(Groceries[1:5])
table(size(Groceries))
#e)
unique(Groceries)
#e)
duplicated(Groceries)
inspect(Groceries[duplicates(Groceries)])
inspect(Groceries[duplicated(Groceries)])
inspect(Groceries[duplicated(Groceries)][1:5])
#f)
itemFrequency(Groceries)
itemFrequencyPLot(Groceries)
itemFrequencyPlot(Groceries)
itemFrequencyPlot(Groceries, topN=5)
itemFrequencyPlot(Groceries, support=0.1)
#i)
fsets <- apriori(Groceries,
parameter = list(sup=0.01,minlen=1,target="frequent itemsets"))
class(fsets)
inspect(sort(fsets)[1:5])
quality(offsets)
quality(fsets)
fsets2 <- apriori(Groceries,
parameter = list(sup=0.01,minlen=2,target="frequent itemsets"))
inspect(sort(fsets)[1:5])
inspect(sort(fsets2)[1:5])
fsetsclosed <- fsets[ls,closed(fsets)]
fsetsclosed <- fsets[is.closed(fsets)]
fsetsmax <- fsets(is.maximal(fests))
fsetsmax <- fsets(is.maximal(fsets))
fsetsmax <- fsets[is.maximal(fsets)]
#l)
rules <- apriori(Groceries)
rules <- apriori(Groceries, parameter = list(supp=0.01,conf=0.5))
summary(rules)
require(kernldb)
y<-as.numeric(spam[, ncol(spam)])-1
data(spam)
data(spom)
require(kernlab)
data(spam)
y<-as.numeric(spam[, ncol(spam)])-1
x<- spam[, -col(spam)]
gl = glm(y., data=x,family=binomial)
gl = glm(y ., data=x,family=binomial)
gl = glm(y, data=x,family=binomial)
gl = glm(y ~, data=x,family=binomial)
gl = glm(y ~., data=x,family=binomial)
gl <- glm(y ~., data=x,family=binomial)
y<-as.numeric(spam[, ncol(spam)])-1
x<- spam[, -col(spam)]
gl <- glm(y ~., data=x,family=binomial)
y<-as.numeric(spam[, -ncol(spam)])-1
x<- spam[, -col(spam)]
gl <- glm(y ~., data=x,family=binomial)
y<-as.numeric(spam[, ncol(spam)])-1
x<- spam[, -ncol(spam)]
gl <- glm(y ~., data=x,family=binomial)
library(MASS)
lda-res = lda(x=X[train,],grouping=Y[train])
proba-train = predict(gl,newdata=X[train,],type=”response”)
proba-train = predict(gl,newdata=X[train,],type="response")
proba-train = predict(gl,newdata=x[train,],type="response")
proba = predict(gl,type=”response”)
proba = predict(gl,type="response")
predicted-spam = as.numeric( proba>0.5)
predicted-spam = as.numeric(proba>0.5)
predicted-spam <- as.numeric(proba>0.5)
predicted_spam <- as.numeric(proba>0.5)
table(predicted-spam,Y)
table(predicted_spam,Y)
table(predicted_spam,y)
n = length(y)
s=sample(1:n)
q=round(0.70*n)
train=s[1:q]
test=s[(q+1):n]
gl = glm(Y[train] ., data=x[train,],family=binomial)
gl = glm(y[train] ., data=x[train,],family=binomial)
gl = glm(y[train] ~., data=x[train,],family=binomial)
proba-train = predict(gl,newdata=x[train,],type="response")
proba_train = predict(gl,newdata=x[train,],type="response")
proba_test = predict(gl,newdata=x[test,],type="response")
predicted_spam_train = as.numeric(proba-train>0.99)
predicted_spam_test = as.numeric(proba-test>0.99)
table(predicted_spam_train, Y[train])
proba_train = predict(gl,newdata=x[train,],type="response")
proba_test = predict(gl,newdata=x[test,],type="response")
predicted_spam_train = as.numeric(proba-train>0.99)
predicted_spam_test = as.numeric(proba-test>0.99)
table(predicted_spam_train, y[train])
proba_train = predict(gl,newdata=x[train,],type="response")
proba_test = predict(gl,newdata=x[test,],type="response")
predicted_spam_train = as.numeric(proba_train>0.99)
predicted_spam_test = as.numeric(proba_test>0.99)
table(predicted_spam_train, y[train])
table(predicted_spam_test, y[test])
library(arulesSewuences)
install.packages("arulesSquences")
library(arulesSequences)
install.packages("arulesSequences")
library(arulesSequences)
data("zaki")
inspect(zak)
inspect(zaki)
setwd("~/Documentos/GitHub/COVID19_Taxi_App")
read.csv("anim.csv")
read.csv('anim.csv')
read.csv('anim.csv')
x = read.csv('anim.csv')
summary(x)
View(x)
